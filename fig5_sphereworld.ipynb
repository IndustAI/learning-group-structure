{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vg4cvdelLfu4"
   },
   "source": [
    "# Learning disentangled representations in a 'sphere-world' with continuous actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tCrh9S0cLfu7"
   },
   "source": [
    "## 1. Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "O3DCxPvjLfu7",
    "outputId": "3eb24d59-24f9-4dff-a995-0fba516ce468"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4ab8cfa1badd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import time\n",
    "from IPython import display\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    sns.set()\n",
    "    print(\"Set seaborn plotting defaults.\")\n",
    "except:\n",
    "    print(\"seaborn not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vZT8DJuOLfvA",
    "outputId": "c4b322ab-d0d3-4cb7-9975-78cdcfb8dda6"
   },
   "outputs": [],
   "source": [
    "def mk_dir(export_dir, quite=False):\n",
    "    if not os.path.exists(export_dir):\n",
    "            try:\n",
    "                os.makedirs(export_dir)\n",
    "                print('created dir: ', export_dir)\n",
    "            except OSError as exc: # Guard against race condition\n",
    "                 if exc.errno != exc.errno.EEXIST:\n",
    "                    raise\n",
    "            except Exception:\n",
    "                pass\n",
    "    else:\n",
    "        print('dir already exists: ', export_dir)\n",
    "\n",
    "mk_dir(\"_data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K6pWc-O2LfvE"
   },
   "source": [
    "## 2. Defining objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a9T6w_ulLfvF"
   },
   "source": [
    "### SphereWorld environment\n",
    "\n",
    "We use a cubic 3D world in which a ball evolves on a sphere. Observations are a 3-dimensional tensor with values 0 except at the voxel occupied by the ball which has value 1. When the ball is not at the center of the voxel (which is most of the time) its density is distributed around neighbouring voxels. Actions are continuous rotations around the three axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eKNwZHkdLfvG"
   },
   "outputs": [],
   "source": [
    "class SphereWorld():\n",
    "    \n",
    "    class action_space():\n",
    "        def __init__(self,n_actions):\n",
    "            self.n = n_actions\n",
    "            \n",
    "        def sample(self, k=1):\n",
    "            return torch.randint(0,self.n,(k,))       \n",
    "\n",
    "    class observation_space():\n",
    "        def __init__(self,n_features):\n",
    "            self.shape = [n_features]\n",
    "    \n",
    "    def __init__(self,dim=5,radius=3.5):\n",
    "\n",
    "        self.size = dim\n",
    "\n",
    "        self.radius = radius\n",
    "        self.action_space = self.action_space(6)\n",
    "        self.observation_space = self.observation_space((2*dim)**3)\n",
    "        \n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "\n",
    "        self.theta = random.uniform(0, np.pi)\n",
    "        self.phi = random.uniform(0, np.pi*2)\n",
    "\n",
    "        self.ball_coordinates = [self.radius*np.sin(self.theta)*np.cos(self.phi), \\\n",
    "                                 self.radius*np.sin(self.theta)*np.sin(self.phi), \\\n",
    "                                 self.radius*np.cos(self.theta)]   #Start from an outside position\n",
    "\n",
    "        self.state = self.get_state()\n",
    "        return self.get_observation()\n",
    "    \n",
    "    def get_state(self, ball_coordinates=None):\n",
    "        if ball_coordinates is None:\n",
    "            ball_coordinates=self.ball_coordinates\n",
    "\n",
    "        state = torch.zeros((2*self.size, 2*self.size, 2*self.size))\n",
    "\n",
    "        ball_low_x = ball_coordinates[0] + self.size - .5\n",
    "        ball_low_y = ball_coordinates[1] + self.size - .5\n",
    "        ball_low_z = ball_coordinates[2] + self.size - .5\n",
    "\n",
    "        fill_x = (int(ball_low_x + 1) - ball_low_x)\n",
    "        fill_y = (int(ball_low_y + 1) - ball_low_y)\n",
    "        fill_z = (int(ball_low_z + 1) - ball_low_z)\n",
    "\n",
    "        state[int(ball_low_x), int(ball_low_y), int(ball_low_z)] = fill_x * fill_y * fill_z\n",
    "        state[(int(ball_low_x) + 1), int(ball_low_y), int(ball_low_z)] = (1 - fill_x) * fill_y * fill_z\n",
    "        state[int(ball_low_x), (int(ball_low_y) + 1), int(ball_low_z)] = fill_x * (1 - fill_y) * fill_z\n",
    "        state[(int(ball_low_x) + 1), (int(ball_low_y) +1), int(ball_low_z)] = (1 - fill_x) * (1 - fill_y) * fill_z\n",
    "        state[int(ball_low_x), int(ball_low_y), int(ball_low_z) + 1] = fill_x * fill_y * (1 - fill_z)\n",
    "        state[(int(ball_low_x) + 1), int(ball_low_y), int(ball_low_z) + 1] = (1 - fill_x) * fill_y * (1 - fill_z)\n",
    "        state[int(ball_low_x), (int(ball_low_y) + 1), int(ball_low_z) + 1] = fill_x * (1 - fill_y) * (1 - fill_z)\n",
    "        state[(int(ball_low_x) + 1), (int(ball_low_y) +1), int(ball_low_z) + 1] = (1 - fill_x) * (1 - fill_y) * (1 - fill_z)\n",
    "\n",
    "        self.state = state\n",
    "        return state      \n",
    "\n",
    "    def get_observation(self):\n",
    "        return self.state.flatten()\n",
    "\n",
    "    def step(self, action, angle):\n",
    "\n",
    "        ball_coordinates = self.ball_coordinates\n",
    "\n",
    "        if action == 0:\n",
    "            new_ball_coordinates = [ball_coordinates[0]*np.cos(angle) + ball_coordinates[1]*np.sin(angle), \\\n",
    "                                    - ball_coordinates[0]*np.sin(angle) + ball_coordinates[1]*np.cos(angle), \\\n",
    "                                    ball_coordinates[2]]\n",
    "        elif action == 1:\n",
    "            new_ball_coordinates = [ball_coordinates[0]*np.cos(angle) + ball_coordinates[2]*np.sin(angle), \\\n",
    "                                    ball_coordinates[1], \\\n",
    "                                    - ball_coordinates[0]*np.sin(angle) + ball_coordinates[2]*np.cos(angle)]\n",
    "        elif action == 2:\n",
    "            new_ball_coordinates = [ball_coordinates[0], \\\n",
    "                                    ball_coordinates[1]*np.cos(angle) + ball_coordinates[2]*np.sin(angle), \\\n",
    "                                    - ball_coordinates[1]*np.sin(angle) + ball_coordinates[2]*np.cos(angle)]\n",
    "        else:\n",
    "            raise Exception(\"INVALID ACTION\")\n",
    "\n",
    "        self.ball_coordinates = new_ball_coordinates\n",
    "        self.state = self.get_state()\n",
    "        return self.get_observation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show consecutive states from this environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "id": "nJzVluJvLfvJ",
    "outputId": "4051eda7-133b-4cbf-903f-86e76d9dab47"
   },
   "outputs": [],
   "source": [
    "def plot_state(state, ax):\n",
    "    ax[0].pcolormesh(env.state.sum(axis=0), edgecolors='gray', linewidth=2, )\n",
    "    ax[0].set_aspect('equal')\n",
    "    ax[0].set_xticks([])\n",
    "    ax[0].set_yticks([])\n",
    "\n",
    "    ax[1].pcolormesh(env.state.sum(axis=1), edgecolors='gray', linewidth=2, )\n",
    "    ax[1].set_aspect('equal')\n",
    "    ax[1].set_xticks([])\n",
    "    ax[1].set_yticks([])\n",
    "\n",
    "    ax[2].pcolormesh(env.state.sum(axis=2), edgecolors='gray', linewidth=2, )\n",
    "    ax[2].set_aspect('equal')\n",
    "    ax[2].set_xticks([])\n",
    "    ax[2].set_yticks([])\n",
    "    \n",
    "    return ax\n",
    "    \n",
    "n_steps = 8\n",
    "\n",
    "env = SphereWorld()\n",
    "\n",
    "fig, axs = plt.subplots(3, n_steps+1,figsize=(15, 5))\n",
    "\n",
    "plot_state(env.state,axs[:,0])\n",
    "\n",
    "for i in range(n_steps):\n",
    "    action = 2\n",
    "    env.step(action, np.pi/4)\n",
    "    plot_state(env.state,axs[:,i+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d-YbQlBeLfvL"
   },
   "source": [
    "### Latent space\n",
    "\n",
    "**Encoder/Decoder**\n",
    "\n",
    "Now we want to learn to represent this environment in some latent space (which we, for now, simply assume to be 3-dimensional).  We will require both an encoder and decoder, which will be simple MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mLgin2GfLfvM"
   },
   "outputs": [],
   "source": [
    "class Coder(nn.Module):\n",
    "\n",
    "    def __init__(self, n_in, n_out, n_hid=[16], output_activation=nn.Sigmoid):\n",
    "        super().__init__()\n",
    "        \n",
    "        if type(n_hid) != list:\n",
    "            n_hid = [n_hid]\n",
    "        n_layers = [n_in] + n_hid + [n_out]\n",
    "\n",
    "        self.layers = []\n",
    "        for i_layer, (n1, n2) in enumerate(zip(n_layers, n_layers[1:])):\n",
    "            mods = [nn.Linear(n1, n2, bias=True)]\n",
    "            act_fn = nn.ReLU if i_layer < len(n_layers) - 2 else output_activation\n",
    "            if act_fn is not None:\n",
    "                mods.append(act_fn())\n",
    "            layer = nn.Sequential(*mods)\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        self.layers = nn.ModuleList(self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "class nnNorm(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim=-1):\n",
    "        super().__init__()\n",
    "        self.dim=dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return F.normalize(x, dim=self.dim)\n",
    "    \n",
    "class Decoder(Coder):\n",
    "\n",
    "    def __init__(self, n_in, n_out, n_hid=[32]):\n",
    "        super().__init__(n_in, n_out, n_hid, output_activation=nn.Sigmoid)\n",
    "        \n",
    "class Encoder(Coder):\n",
    "\n",
    "    def __init__(self, n_in, n_out, n_hid=[32]):\n",
    "        super().__init__(n_in, n_out, n_hid, output_activation=nnNorm)\n",
    "\n",
    "class Angles(Coder):\n",
    "\n",
    "    def __init__(self, n_in, n_out, n_hid=[32]):\n",
    "        super().__init__(n_in, n_out, n_hid, output_activation=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "a1kbTenPLfvP",
    "outputId": "021dc17e-189b-4099-ea18-525c8064e6d9"
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(n_in=5*5*5, n_out=6, n_hid=[64])\n",
    "print(encoder)\n",
    "\n",
    "decoder = Decoder(n_in=6, n_out=5*5*5, n_hid=[64])\n",
    "print(decoder)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check tensor dimensions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "Eco7PPZVLfvS",
    "outputId": "1c30aa19-b1c5-4ed2-ff88-488d14294b60"
   },
   "outputs": [],
   "source": [
    "x = torch.rand(125)\n",
    "z = encoder(x)\n",
    "x_recon = decoder(z)\n",
    "print(\"Observable rep (shape = {}) : \\n {}\".format(x.shape, x))\n",
    "print(\"Latent rep (shape = {}, norm = {}) : \\n {}\".format(z.shape, torch.norm(z), z))\n",
    "print(\"Reconstructed Observable rep (shape = {}) : \\n {}\".format(x_recon.shape, x_recon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RxrdJVugLfvV"
   },
   "source": [
    "**Representation**\n",
    "\n",
    "The crux of the matter is learning to 'represent' actions in the observation space with actions in latent space.  Here, we will do this by assuming every action is a generalized rotation in latent space, which we denote with a series of 2-dimensional rotations.\n",
    "\n",
    "A 2-d rotation is given by:\n",
    "\n",
    "\\begin{pmatrix}\n",
    "\\cos(\\theta) & \\sin(\\theta) \\\\\n",
    "-\\sin(\\theta) & \\cos(\\theta)\n",
    "\\end{pmatrix}\n",
    "\n",
    "and we denote a rotation in dimensions $i$ and $j$ of a higher dimensional space as $R_{i,j}(\\theta)$.  For $i=1$, $j=4$, in a 4-dimensional space:\n",
    "\n",
    "\\begin{equation}\n",
    "R_{1,4}(\\theta) = \n",
    "\\begin{pmatrix}\n",
    "\\cos(\\theta) & 0 & 0 & \\sin(\\theta) \\\\\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 \\\\\n",
    "-\\sin(\\theta) & 0 & 0 & \\cos(\\theta)\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "An arbitrary rotation, denoted $g$ as I am subtly moving towards this being a group action, can then be written as:\n",
    "\n",
    "\\begin{equation}\n",
    "    g(\\theta_{1,2},\\theta_{1,3},\\dots,\\theta_{n-1,n}) = \\prod_{i=1}^{n-1} \\prod_{j=1+1}^{n} R_{i,j}(\\theta_{i,j})\n",
    "\\end{equation}\n",
    "\n",
    "which has $n(n-1)/2$ free parameters (i.e. $\\theta_{i,j}$'s).\n",
    "\n",
    "To learn continuous Lie groups instead of discrete rotations, each of these $\\theta_{i,j}$ is now parameterized by a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cep0BxP6LfvV"
   },
   "outputs": [],
   "source": [
    "class Representation():\n",
    "\n",
    "    def __init__(self, dim=3):\n",
    "        self.dim = dim\n",
    "        self.params = dim*(dim-1)//2\n",
    "        self.thetas = torch.autograd.Variable(2*torch.rand(self.params)-1, requires_grad=True)\n",
    "\n",
    "        self.__matrix = None\n",
    "    \n",
    "    def set_thetas(self, thetas):\n",
    "        self.thetas = thetas\n",
    "        self.clear_matrix()\n",
    "    \n",
    "    def clear_matrix(self):\n",
    "        self.__matrix = None\n",
    "        \n",
    "    def get_matrix(self):\n",
    "        if self.__matrix is None:\n",
    "            k = 0\n",
    "            mats = []\n",
    "            for i in range(self.dim-1):\n",
    "                for j in range(self.dim-1-i):\n",
    "                    theta_ij = self.thetas[k]\n",
    "                    k+=1\n",
    "                    c, s = torch.cos(theta_ij), torch.sin(theta_ij)\n",
    "\n",
    "                    rotation_i = torch.eye(self.dim, self.dim)\n",
    "                    rotation_i[i, i] = c\n",
    "                    rotation_i[i, i+j+1] = s\n",
    "                    rotation_i[j+i+1, i] = -s\n",
    "                    rotation_i[j+i+1, j+i+1] = c\n",
    "\n",
    "                    mats.append(rotation_i)\n",
    "\n",
    "            def chain_mult(l):\n",
    "                if len(l)>=3:\n",
    "                    return l[0]@l[1]@chain_mult(l[2:])\n",
    "                elif len(l)==2:\n",
    "                    return l[0]@l[1]\n",
    "                else:\n",
    "                    return l[0]\n",
    "\n",
    "            self.__matrix = chain_mult(mats)\n",
    "                                    \n",
    "        return self.__matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ukE8Gp7SLfvX"
   },
   "source": [
    "**LatentWorld**\n",
    "\n",
    "Now, for symmetry's sake, we'll also have a `LatentWorld` which acts as the environment in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "azhcq0caLfvY"
   },
   "outputs": [],
   "source": [
    "class LatentWorld():\n",
    "    \n",
    "    class action_space():\n",
    "        def __init__(self,n_actions):\n",
    "            self.n = n_actions\n",
    "            \n",
    "        def sample(self, k=1):\n",
    "            return torch.randint(0,self.n,(k,))\n",
    "\n",
    "    class observation_space():\n",
    "        def __init__(self,n_features):\n",
    "            self.shape = [n_features]\n",
    "    \n",
    "    def __init__(self,\n",
    "                 dim=3,\n",
    "                 n_actions=3,\n",
    "                 n_hid=[64]):\n",
    "\n",
    "        self.dim = dim\n",
    "        self.angle_computer = Angles(n_in = 2, n_out = dim*(dim-1)//2, n_hid=n_hid)\n",
    "        self.action_space = self.action_space(n_actions)\n",
    "        self.observation_space = self.observation_space(dim)\n",
    "        \n",
    "        self.representation = Representation()\n",
    "        \n",
    "    def reset(self, state):\n",
    "        self.state = state\n",
    "        return self.get_observation()\n",
    "    \n",
    "    def clear_representations(self):\n",
    "        self.representation.clear_matrix()\n",
    "            \n",
    "    def get_representation_params(self):\n",
    "        params = []\n",
    "        for rep in self.action_reps:\n",
    "            params.append(rep.thetas)\n",
    "        return params\n",
    "    \n",
    "    def save_representations(self, path):\n",
    "        if os.path.splitext(path)[-1] != '.pth':\n",
    "            path += '.pth'\n",
    "        return torch.save(self.angle_computer.state_dict(), path)\n",
    "    \n",
    "    def load_reprentations(self, path):\n",
    "        self.representation.load_state_dict(torch.load(path))\n",
    "            \n",
    "    def get_observation(self):\n",
    "        return self.state\n",
    "    \n",
    "    def step(self,action_value):\n",
    "        self.representation.set_thetas(self.angle_computer(action_value))\n",
    "        self.state = torch.mv(self.representation.get_matrix(), self.state)\n",
    "        obs = self.get_observation()\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wuNAMNxVLfvr"
   },
   "source": [
    "## 5. Disentanglement\n",
    "\n",
    "***Some jargon***\n",
    "\n",
    "We focus on learning a *disentangled* representation of the actions.\n",
    "\n",
    "Before considering how best to do this, we want to define a metric of 'disentanglement'.  We consider the evolution of an observable (latent) vector, $x \\in X$ ($z \\in Z$), under the element $g \\in G$ of the group of symmetries generating transformations of the object.  Then we are looking for a representation, $\\rho:G \\rightarrow GL(V)$, such that the transformation is linear in the latent space, i.e.\n",
    "\\begin{equation}\n",
    "    z^{\\prime} = \\rho(g) \\cdot z.\n",
    "\\end{equation}\n",
    "Note, in our case, the representations are the rotation matrices we learn.\n",
    "\n",
    "For this representation to be disentangled, it means that if there exists a subgroup decomposition of $G$\n",
    "\\begin{equation}\n",
    "    G = G_1 \\times G_2 \\times \\dots \\times G_n,\n",
    "\\end{equation}\n",
    "then we equivalently decompose the representation, $(\\rho, G)$, into subrepresentations:\n",
    "\\begin{equation}\n",
    "    V = V_1 \\oplus V_2 \\oplus \\dots \\oplus V_n\n",
    "\\end{equation}\n",
    "such that the restricted subrepresentations $(\\rho_{\\vert G_i}, V_i)_i$ are non-trivial, and the restricted subrepresentations $(\\rho_{\\vert G_i}, V_j)_{j \\neq i}$ are trivial.\n",
    "\n",
    "In our context, a SphereWorld can be represented as a subgroup of $\\mathrm{SO}(3)$, therefore we hope to find the disentangled representation of the three continuous rotations.\n",
    "\n",
    "***Some practicalities***\n",
    "\n",
    "Our intuition is that the disentangled representation acts as the identity on as many dimensions as possible.  We could attempt to enforce this with some regularization during training.  Normal weight decay won't cut it, as that tries to reduce all weights, where as what we really want to do is have all *but one* of our thetas (which corresponds to the rotation/coupling of two dimensions) to be zero.\n",
    "\n",
    "**1. Entanglement regularisation**\n",
    "\n",
    "So for $m$ parameters, ${\\theta_1, \\dots, \\theta_m}$, we want to regularise with\n",
    "\\begin{equation}\n",
    "    \\sum_{i \\neq j} \\vert\\theta_i\\vert^2, \\mathrm{where\\ } \\theta_j {=} \\mathrm{max_k}({\\vert\\theta_k\\vert}).\n",
    "\\end{equation}\n",
    "We will also use this term as our metric of 'entanglement'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LY1Jk0TqLfvr",
    "outputId": "8ad90339-5eb2-48a6-a10a-24724d81e03b"
   },
   "outputs": [],
   "source": [
    "def calc_entanglement(params):\n",
    "    params = params.abs().pow(2)\n",
    "    return params.sum() - params.max()\n",
    "\n",
    "params = torch.FloatTensor([1,1,0.5,0,0])\n",
    "calc_entanglement(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IHlJMPneLfvw"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hSUBy6XTLfvx"
   },
   "outputs": [],
   "source": [
    "obs_env = SphereWorld(dim = 5, radius = 4.)\n",
    "lat_env = LatentWorld(dim = 4,\n",
    "                      n_actions = obs_env.action_space.n\n",
    "                     )\n",
    "decoder = Decoder(n_in = sum(lat_env.observation_space.shape),\n",
    "                  n_out = sum(obs_env.observation_space.shape),\n",
    "                  n_hid = [64])\n",
    "\n",
    "encoder = Encoder(n_in = sum(obs_env.observation_space.shape),\n",
    "                  n_out = sum(lat_env.observation_space.shape),\n",
    "                  n_hid = [64])\n",
    "\n",
    "optimizer_dec = optim.Adam(decoder.parameters(),\n",
    "                           lr=1e-2,\n",
    "#                            betas=(0.9, 0.99),\n",
    "                           weight_decay=0)\n",
    "\n",
    "optimizer_enc = optim.Adam(encoder.parameters(),\n",
    "                           lr=1e-2,\n",
    "#                            betas=(0.9, 0.99),\n",
    "                           weight_decay=0)\n",
    "\n",
    "optimizer_rep = optim.Adam(lat_env.angle_computer.parameters(),\n",
    "                           lr=1e-2,\n",
    "#                            betas=(0.9, 0.99),\n",
    "                           weight_decay=0)\n",
    "\n",
    "losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wFgbK3o1Lfv1",
    "outputId": "a1dfa56a-cdbd-4e94-e5b0-38cc9a40fde6"
   },
   "outputs": [],
   "source": [
    "n_sgd_steps = 10000\n",
    "ep_steps = 5\n",
    "batch_eps = 16\n",
    "\n",
    "#Starting by learning small angles before moving on the larger angles helps\n",
    "angle_max = np.pi * 2 / 5\n",
    "\n",
    "i = 1\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "temp = 0\n",
    "\n",
    "while i < n_sgd_steps:\n",
    "    if i == 4000:\n",
    "        angle_max = np.pi * 4 / 5\n",
    "    if i == 7000:\n",
    "        angle_max = np.pi\n",
    "\n",
    "    loss = torch.zeros(1)\n",
    "    \n",
    "    for _ in range(batch_eps):\n",
    "        t_ep = -1\n",
    "        while t_ep < ep_steps:\n",
    "            angle = random.uniform(-angle_max, angle_max)\n",
    "            if t_ep == -1:\n",
    "                obs_x = obs_env.reset()\n",
    "                obs_z = lat_env.reset(encoder(obs_x))\n",
    "            else:\n",
    "                action = random.randrange(3)\n",
    "                obs_x = obs_env.step(action, angle)\n",
    "                obs_z = lat_env.step(torch.tensor([action, angle]))\n",
    "            \n",
    "            t_ep += 1         \n",
    "            \n",
    "            obs_x_recon = decoder(obs_z)\n",
    "            (obs_x_recon==obs_x_recon.max()).float()\n",
    "\n",
    "            loss += F.binary_cross_entropy(obs_x_recon, obs_x)\n",
    "            loss += calc_entanglement(lat_env.angle_computer(torch.tensor([action, angle])))*1e-3\n",
    "\n",
    "\n",
    "    loss /= (batch_eps * ep_steps)\n",
    "    loss_raw = loss\n",
    "\n",
    "    losses.append(loss_raw.item())\n",
    "\n",
    "    optimizer_dec.zero_grad()\n",
    "    optimizer_rep.zero_grad()\n",
    "    optimizer_enc.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_dec.step()\n",
    "    optimizer_rep.step()\n",
    "    optimizer_enc.step()\n",
    "        \n",
    "    # Rember to clear the cached action representations after we update the parameters!\n",
    "    lat_env.clear_representations()\n",
    "\n",
    "    i+=1\n",
    "    \n",
    "    if i%10==0:\n",
    "        print(\"iter {} : loss={:.5f} : last 10 iters in {:.3f}s\".format(\n",
    "            i, loss.item(), time.time() - t_start\n",
    "            ), end=\"\\r\" if i%100 else \"\\n\")\n",
    "        t_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "7QC0cpblLfv3",
    "outputId": "a832e943-86eb-4796-b706-1e346011c3ea"
   },
   "outputs": [],
   "source": [
    "exp_name = \"ent_reg_1e-2_orthNorm_reg_1e-2_20steps_16batch\"\n",
    "# exp_name = \"testing\"\n",
    "\n",
    "save_folder = os.path.join(\"_data/decoder_only\", exp_name)\n",
    "train_folder = os.path.join(save_folder,\"train\")\n",
    "test_folder = os.path.join(save_folder,\"test\")\n",
    "\n",
    "mk_dir(save_folder)\n",
    "mk_dir(train_folder)\n",
    "mk_dir(test_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot training curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "colab_type": "code",
    "id": "8ZvGlRhrLfv7",
    "outputId": "27abcd7b-b11d-4684-8764-acca7fb86d72"
   },
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-paper', after_reset=True):\n",
    "\n",
    "    fig, (ax1) = plt.subplots(1, 1, figsize=(8, 8), gridspec_kw={\"wspace\":0.3})\n",
    "\n",
    "    window = 25\n",
    "    avg_mask = np.ones(window) / window\n",
    "\n",
    "    ax1.plot(np.convolve(range(len(losses)), avg_mask, 'valid'),\n",
    "             np.convolve(np.log(losses), avg_mask, 'valid'),\n",
    "             linewidth=0.75,\n",
    "             alpha=0.8)\n",
    "#     ax1.set_yscale(\"log\")\n",
    "\n",
    "    ax1.set_xlabel(\"Num. parameter updates\")\n",
    "    ax1.set_ylabel(\"Log reconstruction loss\")\n",
    "    \n",
    "    fig_fname = os.path.join(train_folder, \"training_curves\")\n",
    "    plt.savefig(fig_fname + \".pdf\", bbox_inches='tight')\n",
    "    plt.savefig(fig_fname + \".png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "NIoWghTALfv9",
    "outputId": "cb5d7bf4-0ab6-4dc4-cf5e-d5c0ded5d6d2"
   },
   "outputs": [],
   "source": [
    "torch.save(decoder.state_dict(), os.path.join(save_folder,\"decoder.pth\"))\n",
    "torch.save(optimizer_dec.state_dict(), os.path.join(train_folder,\"optimizer_dec.pth\"))\n",
    "torch.save(optimizer_rep.state_dict(), os.path.join(train_folder,\"optimizer_rep.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UEa4HWOULfwA"
   },
   "source": [
    "### Testing\n",
    "\n",
    "**1) Representations learned for specific values of the rotations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 740
    },
    "colab_type": "code",
    "id": "lT3q-ZeWLfwB",
    "outputId": "b0359caf-4a30-4487-8932-9209b1954c86"
   },
   "outputs": [],
   "source": [
    "width=0.75\n",
    "\n",
    "\n",
    "plt_lim = 0.22\n",
    "titles = [\"-0.2\", \"-0.1\", \"0\", \"0.1\", \"0.2\"]\n",
    "\n",
    "with plt.style.context('seaborn-paper', after_reset=True):\n",
    "\n",
    "    fig, axs = plt.subplots(3, 5, figsize=(15, 5), gridspec_kw={\"wspace\":0.4})\n",
    "    \n",
    "    for i in range(15):\n",
    "        thetas = lat_env.angle_computer(torch.tensor([i//5, (-0.2+(i%5)/10.)*2*np.pi])).detach()\n",
    "        print(thetas)\n",
    "        x = np.arange(len(thetas))\n",
    "        axs[i//5,i%5].bar(x - width/2, thetas/(2*np.pi), width, label='Rep {}'.format(i))\n",
    "        \n",
    "        axs[i//5,i%5].set_yticks([-0.2, 0., 0.2])\n",
    "        axs[i//5,i%5].set_xticks(x-0.25)\n",
    "        axs[i//5,i%5].set_xticklabels([\"12\",\"13\",\"23\"])\n",
    "        axs[i//5,i%5].set_xlabel(\"$ij$\")\n",
    "        \n",
    "        axs[i//5,i%5].set_ylim(-plt_lim,plt_lim)\n",
    "        \n",
    "        axs[i//5,i%5].set_title(titles[i%5])\n",
    "        \n",
    "    axs[0,0].set_ylabel(r\"$x : \\theta / 2\\pi$\" )\n",
    "    axs[1,0].set_ylabel(r\"$y : \\theta / 2\\pi$\" )\n",
    "    axs[2,0].set_ylabel(r\"$y : \\theta / 2\\pi$\" )    \n",
    "\n",
    "    fig_fname = os.path.join(test_folder, \"thetas\")\n",
    "\n",
    "    plt.savefig(fig_fname + \".pdf\", bbox_inches='tight')\n",
    "    plt.savefig(fig_fname + \".png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Learned representations as a function of rotation angle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "z9zp45gzAolz",
    "outputId": "b3dee0d8-2fd2-4f93-e997-9b535a9acb7f"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(17, 5))\n",
    "\n",
    "x = np.linspace(-np.pi, np.pi, 500)\n",
    "\n",
    "titles = [\"rotation around $x$\", \"rotation around $y$\", \"rotation around $z$\"]\n",
    "\n",
    "for i in range(3):\n",
    "    y0 = []\n",
    "    y1 = []\n",
    "    y2 = []\n",
    "    for k in range(500):\n",
    "        y = lat_env.angle_computer(torch.tensor([i, x[k]])).detach().numpy()\n",
    "        y0 += [y[0]]\n",
    "        y1 += [y[1]]\n",
    "        y2 += [y[2]]\n",
    "    a = axs[i].plot(x,y0,c=\"r\",linewidth=2)[0]\n",
    "    b = axs[i].plot(x,y1,c=\"b\",linewidth=2)[0]\n",
    "    c = axs[i].plot(x,y2,c=\"g\",linewidth=2)[0]\n",
    "    axs[i].set_xlabel(\"rotation angle\", fontsize=24)\n",
    "    axs[i].set_title(titles[i], fontsize=24)\n",
    "    axs[i].tick_params(labelsize=18)\n",
    "axs[0].set_ylabel(r\"$\\theta_{ij}$\", fontsize=24)\n",
    "fig.subplots_adjust(right=0.83)\n",
    "fig.legend((a,b,c),(r'ij=12',r'ij=13',r'ij=23'), loc='center right',fontsize=24)\n",
    "fig.show()\n",
    "plt.savefig(\"lie_group.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) See predictions made by network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "colab_type": "code",
    "id": "vuARW9LtLfwF",
    "outputId": "b3cc0099-c1fc-4119-9ad8-d60477ecf06f"
   },
   "outputs": [],
   "source": [
    "def plot_state(obs, ax, one_hot=True):\n",
    "    if one_hot:\n",
    "        obs=(obs == obs.max())\n",
    "    ax.pcolormesh(obs.reshape(2*obs_env.size, 2*obs_env.size, 2*obs_env.size).sum(axis=2), edgecolors='gray', linewidth=2)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    return ax\n",
    "    \n",
    "n_steps = 10\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(2, 1)\n",
    "\n",
    "ax1.set_title(\"Ground truth\")\n",
    "ax2.set_title(\"Reconstruction\")\n",
    "\n",
    "for i in range(n_steps+1):\n",
    "    \n",
    "    if i==0:\n",
    "        action = \"N\\A\"\n",
    "        obs_x = obs_env.reset()\n",
    "        obs_z = lat_env.reset(encoder(obs_x))\n",
    "    else:\n",
    "        action = random.randrange(3)\n",
    "        angle = random.uniform(-angle_max, angle_max)\n",
    "        obs_x = obs_env.step(action, angle)\n",
    "        obs_z = lat_env.step(torch.tensor([action, angle]))\n",
    "        \n",
    "    obs_x_recon = decoder(obs_z)\n",
    "    \n",
    "    fig.suptitle('step {} : last action = {} in the x-y plane'.format(i, action), fontsize=16)\n",
    "    \n",
    "    plot_state(obs_x.detach().numpy(),ax1)\n",
    "    plot_state(obs_x_recon.detach().numpy(),ax2, one_hot=False)\n",
    "    \n",
    "    fig_fname = os.path.join(test_folder, \"step_{}\".format(i))\n",
    "\n",
    "    plt.savefig(fig_fname + \".pdf\", bbox_inches='tight')\n",
    "    plt.savefig(fig_fname + \".png\", bbox_inches='tight')\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    time.sleep(1.)\n",
    "    \n",
    "display.clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sphere-world.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
